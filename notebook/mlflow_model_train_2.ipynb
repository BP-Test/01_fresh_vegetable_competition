{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "sys.dont_write_bytecode = True  # __pycache__ 生成を防ぐ\n",
    "from vege_train_memo import Model, Experiments\n",
    "\n",
    "\n",
    "# default\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Manage experiments\n",
    "import mlflow\n",
    "\n",
    "# For training\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import model framework\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "# mlflow setting\n",
    "DB_PATH = '../server/mlruns.db'\n",
    "ARTIFACT_LOCATION = '../data/'\n",
    "EXPERIMENT_NAME = '02_model_train'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "all_df = pd.read_csv('../data/model_input_data.csv')  # , index_col=0)\n",
    "\n",
    "\n",
    "grouping_by = 'kind'\n",
    "target_vege_type = set(all_df[grouping_by])\n",
    "\n",
    "Y_column_name = 'mode_price'\n",
    "X_column_name = set(all_df.head().select_dtypes(\n",
    "    float).columns) - set(Y_column_name)\n",
    "\n",
    "for vege_type in target_vege_type:\n",
    "    # 特定の野菜について取り出す\n",
    "    df = all_df[all_df[grouping_by] == vege_type].select_dtypes(\n",
    "        float).astype('float32')\n",
    "    # 'mode_price'に欠損がない部分を訓練データとして利用する\n",
    "    train = df[~df[Y_column_name].isna()]\n",
    "\n",
    "    # 目的変数の切り分け\n",
    "    X = train[X_column_name].to_numpy()\n",
    "    Y = train[Y_column_name].to_numpy()\n",
    "\n",
    "    #X_train, X_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 元コード（メモ）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "\n",
    "# device setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class BiLSTMEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, lstm_dim, vocab_size):\n",
    "        super(BiLSTMEncoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.lstm_dim = lstm_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # bidirectional=Trueでお手軽に双方向のLSTMにできる\n",
    "        self.bilstm = nn.LSTM(embedding_dim, lstm_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "    def forward(self, text):\n",
    "        embeds = self.word_embeddings(text)\n",
    "\n",
    "        # 各隠れ層のベクトルがほしいので第１戻り値を受け取る\n",
    "        out, _ = self.bilstm(embeds)\n",
    "\n",
    "        # 前方向と後ろ方向の各隠れ層のベクトルを結合したままの状態で返す\n",
    "        return out\n",
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "  def __init__(self, lstm_dim, da, r):\n",
    "    super(SelfAttention, self).__init__()\n",
    "    self.lstm_dim = lstm_dim\n",
    "    self.da = da\n",
    "    self.r = r\n",
    "    self.main = nn.Sequential(\n",
    "        # Bidirectionalなので各隠れ層のベクトルの次元は２倍のサイズになってます。\n",
    "        nn.Linear(lstm_dim * 2, da), \n",
    "        nn.Tanh(),\n",
    "        nn.Linear(da, r)\n",
    "    )\n",
    "  def forward(self, out):\n",
    "    return F.softmax(self.main(out), dim=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SelfAttentionClassifier(nn.Module):\n",
    "  def __init__(self, lstm_dim, da, r, tagset_size):\n",
    "    super(SelfAttentionClassifier, self).__init__()\n",
    "    self.lstm_dim = lstm_dim\n",
    "    self.r = r\n",
    "    self.attn = SelfAttention(lstm_dim, da, r)\n",
    "    self.main = nn.Linear(lstm_dim * 6, tagset_size)\n",
    "\n",
    "  def forward(self, out):\n",
    "    attention_weight = self.attn(out)\n",
    "    m1 = (out * attention_weight[:,:,0].unsqueeze(2)).sum(dim=1)\n",
    "    m2 = (out * attention_weight[:,:,1].unsqueeze(2)).sum(dim=1)\n",
    "    m3 = (out * attention_weight[:,:,2].unsqueeze(2)).sum(dim=1)\n",
    "    feats = torch.cat([m1, m2, m3], dim=1)\n",
    "    return F.log_softmax(self.main(feats)), attention_weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('conda_py38')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3bde98ef8fa1e663dc229e7ead5f65fddc164c0dab2fc22d4e7d4daf7dcee8d2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
